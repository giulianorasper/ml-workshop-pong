{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "import pong\n",
    "import printing\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    import os\n",
    "    os.environ['SDL_VIDEODRIVER']='dummy'\n",
    "\n",
    "from pong import Pong\n",
    "from pong_observer import Player\n",
    "from main import train\n",
    "import strategy_pattern\n",
    "from typing import List\n",
    "from strategy_pattern import Strategy\n",
    "from play import play\n",
    "from pong_action import PongAction\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting to know the environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Play a game of pong!\n",
    "W/S: move left paddle up/down\n",
    "UP/DOWN: move right paddle up/down"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "play()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What do you think, how long it will take until you can see a learning effect?\n",
    "Run the training and find out!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strategy_pattern.strategies = {}\n",
    "train(training_time=60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next you will implement the relevant methods for a successful training yourself."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining the action space"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Teach the neural network which actions exist by assigning a number to each action."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_action_map():\n",
    "    return {\n",
    "        0: PongAction(True, False), # move paddle up\n",
    "        # 1: ...\n",
    "        # 2: ...\n",
    "    }\n",
    "strategy_pattern.strategies[Strategy.ACTION_MAP] = get_action_map"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining the state space"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The input to a neural network are always numbers or a tuple of numbers; e.g. `(12, 3, 4, 5)`.\n",
    "We cant just throw a `Pong` object into the neural network and say \"learn from this\".\n",
    "Extract the relevant information from the `Pong` object and return it as a tuple of numbers.\n",
    "Note: Press `CTRL` and click on `Pong` in the code to go to the definition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_state(observation: Pong) -> tuple:\n",
    "    return observation.ticks_this_ball_exchange, 42, 99 # ,observation.somethingElse,...\n",
    "\n",
    "strategy_pattern.strategies[Strategy.STATE] = get_state"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test if you give the neural network the right information:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(training_time=60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining the structure of the neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's not rely on the code to automatically create a neural network for us.\n",
    "What do you think, from what we did earlier, influences how the neural network must be structured?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remember, we use a list notation to define the structure of the neural network.\n",
    "E.g. E.g. `[4, 2, 3, 1]` created the following neural network:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open(\"nn_structure.png\")\n",
    "display(im)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement you own network structure!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_network_structure() -> List[int]:\n",
    "    # a neural network with 1 input, two hidden layers of size 2 and 1 output\n",
    "    return [1, 2, 2, 1]\n",
    "\n",
    "strategy_pattern.strategies[Strategy.NETWORK_STRUCTURE] = get_network_structure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see if it works!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(training_time=60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining a reward function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will define a reward function i.e. tell the neural network what it did right and what it did wrong.\n",
    "But first, let's define a few helper functions:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def enemy_scored(observation: Pong, next_observation: Pong) -> bool:\n",
    "    \"\"\"\n",
    "    Did the enemy score a point?\n",
    "    :param observation: how the game state looks like\n",
    "    :param next_observation: how the game state looks like shortly after\n",
    "    :return: True if the enemy scored a point, False otherwise\n",
    "    :note: The enemy is the right side player!\n",
    "    \"\"\"\n",
    "    return True # replace with your own logic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def how_far_is_ball_from_left_paddle(observation: Pong) -> float:\n",
    "    \"\"\"\n",
    "    How far is the ball from the paddle (horizontally)?\n",
    "    :param observation: how the game state looks like\n",
    "    :return: The horizontal distance between ball and the left paddle.\n",
    "    \"\"\"\n",
    "    return 0.0 # replace with your own logic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's define the reward function:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_reward(observation: Pong, next_observation: Pong) -> float:\n",
    "    \"\"\"\n",
    "    How good was the action the neural network took?\n",
    "    :param observation: how the game state looks like\n",
    "    :param next_observation: how the game state looks like shortly after\n",
    "    :return: A number indicating how good the action was (positive: good, negative: bad, 0: neutral).\n",
    "    \"\"\"\n",
    "    return 0 # your reward strategy goes here\n",
    "\n",
    "strategy_pattern.strategies = {}\n",
    "strategy_pattern.strategies[Strategy.REWARD] = get_reward"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we actually train the neural network, test if the reward function works as expected.\n",
    "When running the following code, you can control the left paddle while observing the reward printed to the console:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Don't bother with the details of this code, but ask if you are interested\n",
    "import copy\n",
    "flags = copy.copy(printing.print_flags)\n",
    "printing.print_flags.append(printing.PrintFlag.REWARD)\n",
    "try:\n",
    "    play(invincible_enemy=True, debug=True)\n",
    "finally:\n",
    "    printing.print_flags = flags"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see if it works!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(training_time=60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transforming observations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have trained our agent on the left hand side, lets try it for the other side too!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "play(ai_enemy=True, swap_players=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What do you think? Great?!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement a function which \"transforms\" the observations,\n",
    "such that we can leverage what we already learned."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transform_observation(observation: Pong) -> Pong:\n",
    "    width = pong.width\n",
    "    height = pong.height\n",
    "\n",
    "strategy_pattern.strategies[Strategy.TRANSFORM_OBSERVATION] = transform_observation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try again!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "play(ai_enemy=True, swap_players=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
